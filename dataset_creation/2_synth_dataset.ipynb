{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb6bf876-2014-4c91-8e1f-0d69b5db7c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede34ec1-c70e-4c2a-9a30-b597e6772515",
   "metadata": {},
   "source": [
    "### 1. create the structure of the dataset (context_qa type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "980114cb-9ca2-43ab-a13e-43443bd62e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dictonary(c,q):\n",
    "    dictionary = {\n",
    "        \"context\":\"table(\"+c+\")\",\n",
    "        \"question\":q['question'],\n",
    "        \"answer\":q['answer'],\n",
    "    }\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537fb1be-e693-4442-a623-ea477e0d9fc8",
   "metadata": {},
   "source": [
    "### 2. Synthetic data\n",
    "A simple example: to automate the process, you should randomly generate object poses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93c72e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_dataset_and_qa():\n",
    "    # Define object names\n",
    "    fruit = [\"apple\", \"banana\", \"pear\", \"melon\"]\n",
    "    recipient = [\"cup\", \"bowl\", \"box\", \"basket\"]\n",
    "    object_names = fruit + recipient\n",
    "\n",
    "    # Initialize a list to store the final questions and answers\n",
    "    questions_and_answers = []\n",
    "\n",
    "    # Generate dataset with object positions and process them in a single loop\n",
    "    for _ in range(10000):\n",
    "        # Generate positions for each object\n",
    "        objects = [\n",
    "            {\n",
    "                \"name\": name,\n",
    "                \"x\": random.randint(-500, 500),\n",
    "                \"y\": random.randint(-500, 500),\n",
    "                \"z\": random.randint(0, 500),\n",
    "            }\n",
    "            for name in object_names\n",
    "        ]\n",
    "\n",
    "        # Generate the context for this set of objects\n",
    "        context = \"; \".join(f\"{obj['name']} x: {obj['x']}, y: {obj['y']}, z: {obj['z']}\" for obj in objects) + \";\"\n",
    "\n",
    "        # Randomly assign task type based on required proportions\n",
    "        task_type = random.choices(\n",
    "            [\"place_next_to\", \"place_into\", \"invalid_task\"], weights=[0.33, 0.34, 0.33], k=1\n",
    "        )[0]\n",
    "\n",
    "        obj1 = random.choice(objects)\n",
    "\n",
    "        if task_type == \"place_next_to\":\n",
    "            # Ensure obj2 is not the same as obj1 and is not a recipient\n",
    "            obj2 = random.choice(objects)\n",
    "            while obj2['name'] in recipient or obj1 == obj2:\n",
    "                obj2 = random.choice(objects)\n",
    "\n",
    "            x_a, y_a, z_a = obj1['x'], obj1['y'], obj1['z']\n",
    "            x_c, y_c, z_c = obj2['x'], obj2['y'], obj2['z']\n",
    "\n",
    "            # Generate question and answer for \"place next to\"\n",
    "            q = f\"Pick the object {obj1['name']} and place next to the {obj2['name']}.\"\n",
    "            a = (\n",
    "                f\"go to x: {x_a}, y: {y_a}, z: {z_a}+30; \"\n",
    "                f\"go to x: {x_a}, y: {y_a}, z: {z_a}; \"\n",
    "                f\"close the gripper; \"\n",
    "                f\"go to x: {x_c}+10, y: {y_c}, z: {z_c}+10; \"\n",
    "                f\"open the gripper; \"\n",
    "                \"go home;\"\n",
    "            )\n",
    "\n",
    "        elif task_type == \"place_into\":\n",
    "            # Ensure obj2 is a recipient\n",
    "            obj2 = random.choice(objects)\n",
    "            while obj2['name'] not in recipient or obj1 == obj2:\n",
    "                obj2 = random.choice(objects)\n",
    "\n",
    "            x_a, y_a, z_a = obj1['x'], obj1['y'], obj1['z']\n",
    "            x_c, y_c, z_c = obj2['x'], obj2['y'], obj2['z']\n",
    "\n",
    "            # Generate question and answer for \"place into\"\n",
    "            q = f\"Pick the object {obj1['name']} and place it in the {obj2['name']}.\"\n",
    "            a = (\n",
    "                f\"go to x: {x_a}, y: {y_a}, z: {z_a}+30; \"\n",
    "                f\"go to x: {x_a}, y: {y_a}, z: {z_a}; \"\n",
    "                f\"close the gripper; \"\n",
    "                f\"go to x: {x_c}+0, y: {y_c}, z: {z_c}+10; \"\n",
    "                f\"open the gripper; \"\n",
    "                \"go home;\"\n",
    "            )\n",
    "\n",
    "        else:  # \"invalid_task\"\n",
    "            # Ensure obj2 is not a recipient\n",
    "            obj2 = random.choice(objects)\n",
    "            while obj2['name'] not in recipient:\n",
    "                obj2 = random.choice(objects)\n",
    "\n",
    "            # Generate invalid task\n",
    "            q = f\"Pick the object {obj1['name']} and place it in the {obj2['name']}.\"\n",
    "            a = f\"This task cannot be performed as {obj1['name']} is a recipient.\"\n",
    "\n",
    "        # Store the question and answer\n",
    "        questions_and_answers.append({\n",
    "            \"context\": context,\n",
    "            \"question\": q,\n",
    "            \"answer\": a\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return questions_and_answers\n",
    "\n",
    "final_data = generate_dataset_and_qa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "442961f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save in json file\n",
    "with open('data_2.json', 'w') as f:\n",
    "    json.dump(final_data, f, indent=4)\n",
    "\n",
    "\n",
    "# Load the json file\n",
    "with open('data_2.json', 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8690f9c1-47e8-4efb-ac60-bd1469b48315",
   "metadata": {},
   "source": [
    "### 5. Login to HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79eb6f8e-d0d3-4760-b5f6-1fa662e15910",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\RoboLLM\\RoboLLM_venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "access_token = \"secret\"\n",
    "from huggingface_hub import login\n",
    "login(token=\"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\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99796baa-0d52-497c-b6b5-5001d45f3ea3",
   "metadata": {},
   "source": [
    "### 6. Upload the dataset to HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dac2b2f-d22a-47b9-8101-fa957675fd71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 10000 examples [00:00, 259189.24 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 10/10 [00:00<00:00, 1111.07ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:01<00:00,  1.00s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/endritnazifi/test_lab_dataset2/commit/687d3f78a9fe44e18b355da9d4b9595b161fb78b', commit_message='Upload dataset', commit_description='', oid='687d3f78a9fe44e18b355da9d4b9595b161fb78b', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/endritnazifi/test_lab_dataset2', endpoint='https://huggingface.co', repo_type='dataset', repo_id='endritnazifi/test_lab_dataset2'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset('json', data_files='data_2.json')\n",
    "dataset.push_to_hub(\"endritnazifi/test_lab_dataset2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RoboLLM_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
